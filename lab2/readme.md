# 实验二：音频处理与分析

## 项目概述

本项目实现了两个主要功能：(1)音频特征提取与可视化；(2)基于深度学习的城市环境声音分类系统。使用Python与PyTorch框架，结合librosa和torchaudio库进行音频处理，通过VGGish卷积神经网络实现对UrbanSound8K数据集的有效分类。

## 项目结构

- sound1.py: 音频特征提取与可视化模块
- sound2.py: UrbanSound8K数据集音频分类模块
- audio_analysis.png: 输出的音频特征可视化图像
- Loss.png: 训练过程损失函数曲线图
- ConfusionMatrix.png: 分类模型混淆矩阵可视化图像
- lab2.wav: 用于特征提取的音频

## 功能模块

### 1. 音频特征提取与可视化

通过`sound1.py`实现对音频文件的多维特征提取与可视化，主要包括：

- 短时傅里叶变换(STFT)计算与声谱图生成
- 梅尔频谱图计算，更符合人耳感知特性
- 色度频谱图计算，适用于音乐音调分析
- 多维特征的可视化与保存

### 2. UrbanSound8K音频分类系统

通过`sound2.py`实现的音频分类系统，主要包括：

- 自定义UrbanSound8K数据集加载器
- 音频数据预处理：重采样、单声道转换、长度标准化等
- 基于VGGish架构的卷积神经网络
- 模型训练、评估及结果可视化

## 实验结果分析

对于UrbanSound8K数据集的10类城市环境声音分类任务，我们的VGGish模型取得了以下性能：

### 分类性能总览

- **整体准确率**：77%
- **宏平均F1分数**：78%
- **加权平均F1分数**：77%

### 各类别性能分析

从分类报告可以看出：

1. **表现最佳的类别**：
   - 类别6（枪声）：F1=90%，精确率85%，召回率96%
   - 类别7（手提钻）：F1=88%，精确率89%，召回率87%
   - 类别0（空调声）：F1=87%，精确率91%，召回率83%

2. **表现较弱的类别**：
   - 类别2（儿童玩耍声）：F1=62%，精确率65%，召回率60%
   - 类别1（汽车喇叭）：F1=69%，精确率70%，召回率67%
   - 类别9（街头音乐）：F1=68%，精确率74%，召回率63%

3. **数据不平衡现象**：
   - 类别6（枪声）样本量明显少于其他类别（仅69个样本）
   - 类别1（汽车喇叭）样本量也相对较少（88个样本）
   - 其他类别样本量大致平衡（约190-206个样本）

### 结果分析

1. **模型整体表现**：在10类分类任务中达到77%的准确率是一个良好的结果，说明VGGish模型能够有效区分不同类型的城市环境声音。

2. **类别特点分析**：
   - 枪声（类别6）尽管样本量最少，但分类效果最好，说明该类别声音特征非常显著
   - 儿童玩耍声（类别2）分类效果较差，可能是因为其声音模式变化多样，特征不够稳定
   - 街头音乐（类别9）的召回率较低，可能与其他类别存在特征重叠

3. **优化方向**：
   - 对表现较弱的类别可考虑增加样本量或采用数据增强技术
   - 针对类别2、类别1和类别9的特征提取方法可进一步改进
   - 可以尝试调整模型结构或引入注意力机制，提高对复杂声音模式的识别能力

## 环境要求

- Python 3.6+
- PyTorch 1.7+
- torchaudio
- librosa
- matplotlib
- scikit-learn
- pandas
- seaborn
- tqdm

## 使用方法

### 音频特征提取与可视化

```bash
python sound1.py
```

### UrbanSound8K音频分类

```bash
python sound2.py
```
